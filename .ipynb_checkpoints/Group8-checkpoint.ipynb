{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57b8911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 10:46:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark_session = SparkSession.builder\\\n",
    " .master(\"spark://192.168.2.80:7077\") \\\n",
    " .appName(\"Viktor\")\\\n",
    " .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    " .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    " .config(\"spark.shuffle.service.enabled\", False)\\\n",
    " .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    " .config(\"spark.cores.max\", 2)\\\n",
    " .getOrCreate()\n",
    "\n",
    "spark_context = spark_session.sparkContext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5d4aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166666616666670000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:=============================>                             (1 + 1) / 2]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def add(a, b):\n",
    " # associative and commutative!\n",
    " return a + b\n",
    "rdd = spark_session.sparkContext.parallelize(range(10**7))\n",
    "result = rdd.filter(lambda x: x % 2 == 0)\\\n",
    " .map(lambda x: x ** 2)\\\n",
    " .reduce(add)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dedb74f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import hdf5_getters\n",
    "import re\n",
    "import csv\n",
    "\n",
    "class Song:\n",
    "    songCount = 0\n",
    "    # songDictionary = {}\n",
    "\n",
    "    def __init__(self, songID):\n",
    "        self.id = songID\n",
    "        Song.songCount += 1\n",
    "        # Song.songDictionary[songID] = self\n",
    "\n",
    "        self.albumName = None\n",
    "        self.albumID = None\n",
    "        self.artistID = None\n",
    "        self.artistLatitude = None\n",
    "        self.artistLocation = None\n",
    "        self.artistLongitude = None\n",
    "        self.artistName = None\n",
    "        self.danceability = None\n",
    "        self.duration = None\n",
    "        self.genreList = []\n",
    "        self.keySignature = None\n",
    "        self.keySignatureConfidence = None\n",
    "        self.lyrics = None\n",
    "        self.popularity = None\n",
    "        self.tempo = None\n",
    "        self.timeSignature = None\n",
    "        self.timeSignatureConfidence = None\n",
    "        self.title = None\n",
    "        self.year = None\n",
    "\n",
    "    def displaySongCount(self):\n",
    "        print (\"Total Song Count %i\" % Song.songCount)\n",
    "\n",
    "    def displaySong(self):\n",
    "        print (\"ID: %s\" % self.id  ) \n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    #with open('SongCSV.csv', 'w') as outputFile:\n",
    "        #outputFile1 = csv.writer(outputFile)\n",
    "    outputFile1 = open('SongCSV.csv', 'w')\n",
    "    csvRowString = \"\"\n",
    "\n",
    "    #################################################\n",
    "    #if you want to prompt the user for the order of attributes in the csv,\n",
    "    #leave the prompt boolean set to True\n",
    "    #else, set 'prompt' to False and set the order of attributes in the 'else'\n",
    "    #clause\n",
    "    prompt = False\n",
    "    #################################################\n",
    "    if prompt == True:\n",
    "        while prompt:\n",
    "\n",
    "            prompt = False\n",
    "\n",
    "            csvAttributeString = raw_input(\"\\n\\nIn what order would you like the colums of the CSV file?\\n\" +\n",
    "                \"Please delineate with commas. The options are: \" +\n",
    "                \"AlbumName, AlbumID, ArtistID, ArtistLatitude, ArtistLocation, ArtistLongitude,\"+\n",
    "                \" ArtistName, Danceability, Duration, KeySignature, KeySignatureConfidence, Tempo,\" +\n",
    "                \" SongID, TimeSignature, TimeSignatureConfidence, Title, and Year.\\n\\n\" +\n",
    "                \"For example, you may write \\\"Title, Tempo, Duration\\\"...\\n\\n\" +\n",
    "                \"...or exit by typing 'exit'.\\n\\n\")\n",
    "\n",
    "            csvAttributeList = re.split('\\W+', csvAttributeString)\n",
    "            for i, v in enumerate(csvAttributeList):\n",
    "                csvAttributeList[i] = csvAttributeList[i].lower()\n",
    "\n",
    "            for attribute in csvAttributeList:\n",
    "                # print \"Here is the attribute: \" + attribute + \" \\n\"\n",
    "\n",
    "\n",
    "                if attribute == 'AlbumID'.lower():\n",
    "                    csvRowString += 'AlbumID'\n",
    "                elif attribute == 'AlbumName'.lower():\n",
    "                    csvRowString += 'AlbumName'\n",
    "                elif attribute == 'ArtistID'.lower():\n",
    "                    csvRowString += 'ArtistID'\n",
    "                elif attribute == 'ArtistLatitude'.lower():\n",
    "                    csvRowString += 'ArtistLatitude'\n",
    "                elif attribute == 'ArtistLocation'.lower():\n",
    "                    csvRowString += 'ArtistLocation'\n",
    "                elif attribute == 'ArtistLongitude'.lower():\n",
    "                    csvRowString += 'ArtistLongitude'\n",
    "                elif attribute == 'ArtistName'.lower():\n",
    "                    csvRowString += 'ArtistName'\n",
    "                elif attribute == 'Danceability'.lower():\n",
    "                    csvRowString += 'Danceability'\n",
    "                elif attribute == 'Duration'.lower():\n",
    "                    csvRowString += 'Duration'\n",
    "                elif attribute == 'KeySignature'.lower():\n",
    "                    csvRowString += 'KeySignature'\n",
    "                elif attribute == 'KeySignatureConfidence'.lower():\n",
    "                    csvRowString += 'KeySignatureConfidence'\n",
    "                elif attribute == 'SongID'.lower():\n",
    "                    csvRowString += \"SongID\"\n",
    "                elif attribute == 'Tempo'.lower():\n",
    "                    csvRowString += 'Tempo'\n",
    "                elif attribute == 'TimeSignature'.lower():\n",
    "                    csvRowString += 'TimeSignature'\n",
    "                elif attribute == 'TimeSignatureConfidence'.lower():\n",
    "                    csvRowString += 'TimeSignatureConfidence'\n",
    "                elif attribute == 'Title'.lower():\n",
    "                    csvRowString += 'Title'\n",
    "                elif attribute == 'Year'.lower():\n",
    "                    csvRowString += 'Year'\n",
    "                elif attribute == 'Exit'.lower():\n",
    "                    sys.exit()\n",
    "                else:\n",
    "                    prompt = True\n",
    "                    print (\"==============\")\n",
    "                    print (\"I believe there has been an error with the input.\")\n",
    "                    print (\"==============\")\n",
    "                    break\n",
    "\n",
    "                csvRowString += \",\"\n",
    "\n",
    "            lastIndex = len(csvRowString)\n",
    "            csvRowString = csvRowString[0:lastIndex-1]\n",
    "            csvRowString += \"\\n\"\n",
    "            outputFile1.write(csvRowString);\n",
    "            csvRowString = \"\"\n",
    "    #else, if you want to hard code the order of the csv file and not prompt\n",
    "    #the user, \n",
    "    else:\n",
    "        #################################################\n",
    "        #change the order of the csv file here\n",
    "        #Default is to list all available attributes (in alphabetical order)\n",
    "        csvRowString = (\"SongID,AlbumID,AlbumName,ArtistID,ArtistLatitude,ArtistLocation,\"+\n",
    "            \"ArtistLongitude,ArtistName,Danceability,Duration,KeySignature,\"+\n",
    "            \"KeySignatureConfidence,Tempo,TimeSignature,TimeSignatureConfidence,\"+\n",
    "            \"Title,Year\")\n",
    "        #################################################\n",
    "\n",
    "        csvAttributeList = re.split('\\W+', csvRowString)\n",
    "        for i, v in enumerate(csvAttributeList):\n",
    "            csvAttributeList[i] = csvAttributeList[i].lower()\n",
    "        outputFile1.write(\"SongNumber,\");\n",
    "        outputFile1.write(csvRowString + \"\\n\");\n",
    "        csvRowString = \"\"  \n",
    "\n",
    "    #################################################\n",
    "\n",
    "\n",
    "    #Set the basedir here, the root directory from which the search\n",
    "    #for files stored in a (hierarchical data structure) will originate\n",
    "    basedir = \"/user/input/MillionSongSubset/B/H/A\" # \".\" As the default means the current directory\n",
    "    ext = \".h5\" #Set the extension here. H5 is the extension for HDF5 files.\n",
    "    #################################################\n",
    "\n",
    "    #FOR LOOP\n",
    "    for root, dirs, files in os.walk(basedir):   \n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            print (f +\"is file here?\")\n",
    "\n",
    "            songH5File = hdf5_getters.open_h5_file_read(f)\n",
    "            song = Song(str(hdf5_getters.get_song_id(songH5File)))\n",
    "\n",
    "            testDanceability = hdf5_getters.get_danceability(songH5File)\n",
    "            #print (type(testDanceability))\n",
    "            #print ((\"Here is the danceability: \") + str(testDanceability))\n",
    "\n",
    "            song.artistID = str(hdf5_getters.get_artist_id(songH5File))\n",
    "            song.albumID = str(hdf5_getters.get_release_7digitalid(songH5File))\n",
    "            song.albumName = str(hdf5_getters.get_release(songH5File))\n",
    "            song.artistLatitude = str(hdf5_getters.get_artist_latitude(songH5File))\n",
    "            song.artistLocation = str(hdf5_getters.get_artist_location(songH5File))\n",
    "            song.artistLongitude = str(hdf5_getters.get_artist_longitude(songH5File))\n",
    "            song.artistName = str(hdf5_getters.get_artist_name(songH5File))\n",
    "            song.danceability = str(hdf5_getters.get_danceability(songH5File))\n",
    "            song.duration = str(hdf5_getters.get_duration(songH5File))\n",
    "            # song.setGenreList()\n",
    "            song.keySignature = str(hdf5_getters.get_key(songH5File))\n",
    "            song.keySignatureConfidence = str(hdf5_getters.get_key_confidence(songH5File))\n",
    "            # song.lyrics = None\n",
    "            # song.popularity = None\n",
    "            song.tempo = str(hdf5_getters.get_tempo(songH5File))\n",
    "            song.timeSignature = str(hdf5_getters.get_time_signature(songH5File))\n",
    "            song.timeSignatureConfidence = str(hdf5_getters.get_time_signature_confidence(songH5File))\n",
    "            song.title = str(hdf5_getters.get_title(songH5File))\n",
    "            song.year = str(hdf5_getters.get_year(songH5File))\n",
    "\n",
    "            #print song count\n",
    "            csvRowString += str(song.songCount) + \",\"\n",
    "\n",
    "            for attribute in csvAttributeList:\n",
    "                #print (\"Here is the attribute: \" + attribute + \" \\n\")\n",
    "\n",
    "                if attribute == 'AlbumID'.lower():\n",
    "                    csvRowString += song.albumID\n",
    "                elif attribute == 'AlbumName'.lower():\n",
    "                    albumName = song.albumName\n",
    "                    albumName = albumName.replace(',',\"\")\n",
    "                    csvRowString += \"\\\"\" + albumName[2:-1] + \"\\\"\"\n",
    "                elif attribute == 'ArtistID'.lower():\n",
    "                    csvRowString += \"\\\"\" + song.artistID[2:-1] + \"\\\"\"\n",
    "                elif attribute == 'ArtistLatitude'.lower():\n",
    "                    latitude = song.artistLatitude\n",
    "                    if latitude == 'nan':\n",
    "                        latitude = ''\n",
    "                    csvRowString += latitude\n",
    "                elif attribute == 'ArtistLocation'.lower():\n",
    "                    location = song.artistLocation\n",
    "                    location = location.replace(',','')\n",
    "                    csvRowString += \"\\\"\" + location[2:-1] + \"\\\"\"\n",
    "                elif attribute == 'ArtistLongitude'.lower():\n",
    "                    longitude = song.artistLongitude\n",
    "                    if longitude == 'nan':\n",
    "                        longitude = ''\n",
    "                    csvRowString += longitude                \n",
    "                elif attribute == 'ArtistName'.lower():\n",
    "                    csvRowString += \"\\\"\" + song.artistName[2:-1] + \"\\\"\"                \n",
    "                elif attribute == 'Danceability'.lower():\n",
    "                    csvRowString += song.danceability\n",
    "                elif attribute == 'Duration'.lower():\n",
    "                    csvRowString += song.duration\n",
    "                elif attribute == 'KeySignature'.lower():\n",
    "                    csvRowString += song.keySignature\n",
    "                elif attribute == 'KeySignatureConfidence'.lower():\n",
    "                    # print \"key sig conf: \" + song.timeSignatureConfidence                                 \n",
    "                    csvRowString += song.keySignatureConfidence\n",
    "                elif attribute == 'SongID'.lower():\n",
    "                    csvRowString += \"\\\"\" + song.id[2:-1] + \"\\\"\"\n",
    "                elif attribute == 'Tempo'.lower():\n",
    "                    # print \"Tempo: \" + song.tempo\n",
    "                    csvRowString += song.tempo\n",
    "                elif attribute == 'TimeSignature'.lower():\n",
    "                    csvRowString += song.timeSignature\n",
    "                elif attribute == 'TimeSignatureConfidence'.lower():\n",
    "                    # print \"time sig conf: \" + song.timeSignatureConfidence                                   \n",
    "                    csvRowString += song.timeSignatureConfidence\n",
    "                elif attribute == 'Title'.lower():\n",
    "                    csvRowString += \"\\\"\" + song.title[2:-1] + \"\\\"\"\n",
    "                elif attribute == 'Year'.lower():\n",
    "                    csvRowString += song.year\n",
    "                else:\n",
    "                    csvRowString += \"Erm. This didn't work. Error. :( :(\\n\"\n",
    "\n",
    "                csvRowString += \",\"\n",
    "                #print(csvRowString)\n",
    "\n",
    "            #Remove the final comma from each row in the csv\n",
    "            lastIndex = len(csvRowString)\n",
    "            csvRowString = csvRowString[0:lastIndex-1]\n",
    "            csvRowString += \"\\n\"\n",
    "            outputFile1.write(csvRowString)\n",
    "            #print(csvRowString)\n",
    "            #outputFile1.flush()\n",
    "            csvRowString = \"\"\n",
    "            #outputFile1.write(\"\\ntest!\\n\")\n",
    "            songH5File.close()\n",
    "    outputFile1.flush()\n",
    "    outputFile1.close()\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1efbf382",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5267dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=spark_session.read.text(\"hdfs://192.168.2.80:9000/data/hej.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19a517ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "| hhdh|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88b3af30",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tables' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhdf5_getters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m h5 \u001b[38;5;241m=\u001b[39m \u001b[43mhdf5_getters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_h5_file_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs://192.168.2.80:9000/data/MillionSongSubset/A/A/A\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m duration \u001b[38;5;241m=\u001b[39m hdf5_getters\u001b[38;5;241m.\u001b[39mget_duration(h5)\n\u001b[1;32m      4\u001b[0m h5\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/DataEng1-Project-Group-8/hdf5_getters.py:38\u001b[0m, in \u001b[0;36mopen_h5_file_read\u001b[0;34m(h5filename)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_h5_file_read\u001b[39m(h5filename):\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m    Open an existing H5 in read mode.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m    Same function as in hdf5_utils, here so we avoid one import\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtables\u001b[49m\u001b[38;5;241m.\u001b[39mopen_file(h5filename, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tables' is not defined"
     ]
    }
   ],
   "source": [
    "import hdf5_getters\n",
    "h5 = hdf5_getters.open_h5_file_read(\"hdfs://192.168.2.80:9000/data/MillionSongSubset/A/A/A\")\n",
    "duration = hdf5_getters.get_duration(h5)\n",
    "h5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965421ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
